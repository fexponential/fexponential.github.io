<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>fexponential | VLA Mechanistic Interpretability</title>
    <style>
        body { 
            font-family: 'Segoe UI', Helvetica, Arial, sans-serif; 
            line-height: 1.6; 
            color: #333; 
            max-width: 700px; 
            margin: 0 auto; 
            padding: 100px 20px; 
        }
        h1 { 
            color: #2c3e50; 
            margin-bottom: 10px; 
        }
        .subtitle {
            color: #7f8c8d;
            font-size: 1.2em;
            margin-bottom: 40px;
            font-weight: 300;
        }
        .content { 
            background: #fff; 
            border-top: 4px solid #2c3e50; 
            padding-top: 20px;
        }
        .footer { 
            margin-top: 60px; 
            font-size: 0.85em; 
            color: #999; 
            border-top: 1px solid #eee; 
            padding-top: 20px; 
        }
        a { color: #2c3e50; text-decoration: none; font-weight: bold; }
        a:hover { text-decoration: underline; }
    </style>
</head>
<body>

    <h1>fexponential</h1>
    <div class="subtitle">Mechanistic Interpretability for Robot Learning</div>

    <div class="content">
        <p><strong>fexponential</strong> is an independent research initiative focused on safety and interpretability in Embodied AI.</p>
        
        <p>We are currently developing an open-source framework for Mechanistic Interpretability in Vision-Language-Action (VLA) models. Our research aims to address critical reliability failures, such as temporal blindness in long-horizon tasks and the inability to adhere to dynamic safety constraints.</p>
        
    </div>

    <div class="footer">
        <p>&copy; 2025 fexponential.org<br>
        Founder & Lead Researcher: Sai Shubodh<br>
        <a href="mailto:p.saishubodh@gmail.com">Contact</a>
        </p>
    </div>

</body>
</html>
